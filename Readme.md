MAE: 


feats_all[3] → output of layer 11 → shape [B, 1370, 1024]
feats_all[11] → output of layer 17 → shape [B, 1370, 1024]
feats_all[17] → output of layer 23 → shape [B, 1370, 1024]
feats_all[23] → output of layer 31 → shape [B, 1370, 1024]


The keys and the values of the dictionary are getting gradient update during model building 
we have two projection layer 



Epoch 001 | Val Loss:   0.168901
current dict_size is:4279
→ Saved BEST model (val_loss=0.168901)
Epoch 002 | Train Loss: 0
166307                                                                                                   
Epoch 002 | Val Loss:   0.166407
current dict_size is:4348
→ Saved BEST model (val_loss=0.166407)
Epoch 003 | Train Loss: 0.164723                                                                                                   
Epoch 003 | Val Loss:   0.165355
current dict_size is:4392
→ Saved BEST model (val_loss=0.165355)
Epoch 004 | Train Loss: 0.163826                                                                                                   
Epoch 004 | Val Loss:   0.164871
current dict_size is:4440
→ Saved BEST model (val_loss=0.164871)
Epoch 005 | Train Loss: 0.163141                                                                                                   
Epoch 005 | Val Loss:   0.164163
current dict_size is:4482
→ Saved BEST model (val_loss=0.164163)
Epoch 006 | Train Loss: 0.162470                                                                                                   
Epoch 006 | Val Loss:   0.163009
current dict_size is:4556
Epoch 007 | Train Loss: 0162015                                                                                                   
Epoch 007 | Val Loss:   0.162916
current dict_size is:4614
→ Saved BEST model (val_loss=0.162916)
Epoch 008 | Train Loss: 0.161699                                                                                                   
Epoch 008 | Val Loss:   0.162922
poch 009 | Val Loss:   0.162150
current dict_size is:4750
→ Saved BEST model (val_loss=0.162150)
Epoch 010 | Train Loss: 0.161093                                                                                                   
Epoch 010 | Val Loss:   0.162452
Epoch 011 | Train Loss: 0.160855                                                                                                   
Epoch 011 | Val Loss:   0.161826
current dict_size is:4888
→ Saved BEST model (val_loss=0.161826)
Epoch 012 | Train Loss: 0.160723                                                                                                   
Epoch 012 | Val Loss:   0.161667
current dict_size is:4971
Epoch 013 | Train Loss: 0.160514                                                                                                   
Epoch 013 | Val Loss:   0.161505
current dict_size is:5032
→ Saved BEST model (val_loss=0.161505)
Epoch 014 | Train Loss: 0.160448                                                                                                   
Epoch 014 | Val Loss:   0.161118
current dict_size is:5097
→ Saved BEST model (val_loss=0.161118)
Epoch 015 | Train Loss: 0.160296                                                                                                   
Epoch 015 | Val Loss:   0.161324
Epoch 016 | Train Loss: 0.160095                                                                                                   
Epoch 016 | Val Loss:   0.161169
Epoch 017 | Train Loss: 0.160059                                                                                                   
Epoch 017 | Val Loss:   0.161254
Epoch 018 | Train Loss: 0.159985                                                                                                   
Epoch 018 | Val Loss:   0.161025
current dict_size is:5333
→ Saved BEST model (val_loss=0.161025)
Epoch 019 | Train Loss: 0.159822                                                                                                   
Epoch 019 | Val Loss:   0.161164
Epoch 020 | Train Loss: 0.159745                                                                                                   
Epoch 020 | Val Loss:   0.161099
Epoch 021 | Train Loss: 0.159689                                                                                                   
Epoch 021 | Val Loss:   0.160871
current dict_size is:5513
→ Saved BEST model (val_loss=0.160871)
Epoch 022 | Train Loss: 0.159491                                                                                                   
Epoch 022 | Val Loss:   0.160997
Epoch 023 | Train Loss: 0.159446                                                                                                   
Epoch 023 | Val Loss:   0.160403
current dict_size is:5636
→ Saved BEST model (val_loss=0.160403)
Epoch 024 | Train Loss: 0.159399                                                                                                   
Epoch 024 | Val Loss:   0.160335
current dict_size is:5711
→ Saved BEST model (val_loss=0.160335)
Epoch 025 | Train Loss: 0.159337                                                                                                   
Epoch 025 | Val Loss:   0.160741
Epoch 026 | Train Loss: 0.159326                                                                                                   
Epoch 026 | Val Loss:   0.160304
current dict_size is:5852
→ Saved BEST model (val_loss=0.160304)
Epoch 027 | Train Loss: 0.159291                                                                                                   
Epoch 027 | Val Loss:   0.160511
Epoch 028 | Train Loss: 0.159109                                                                                                   
Epoch 028 | Val Loss:   0.160181
current dict_size is:5965
→ Saved BEST model (val_loss=0.160181)
Epoch 029 | Train Loss: 0.159067                                                                                                   
Epoch 029 | Val Loss:   0.160201
Epoch 030 | Train Loss: 0.159091                                                                                                   
Epoch 030 | Val Loss:   0.160276
Epoch 031 | Train Loss: 0.159024                                                                                                   
Epoch 031 | Val Loss:   0.159984
current dict_size is:6137
→ Saved BEST model (val_loss=0.159984)
Epoch 032 | Train Loss: 0.159045                                                                                                   
Epoch 032 | Val Loss:   0.160224
Epoch 033 | Train Loss: 0.158906                                                                                                   
Epoch 033 | Val Loss:   0.159976
current dict_size is:6236
→ Saved BEST model (val_loss=0.159976)
Epoch 034 | Train Loss: 0.158907                                                                                                   
Epoch 034 | Val Loss:   0.159785
current dict_size is:6298
→ Saved BEST model (val_loss=0.159785)
Epoch 035 | Train Loss: 0.158804                                                                                                   
Epoch 035 | Val Loss:   0.160137
Epoch 036 | Train Loss: 0.158787                                                                                                   
Epoch 036 | Val Loss:   0.160067
Epoch 037 | Train Loss: 0.158803                                                                                                   
Epoch 037 | Val Loss:   0.159929
Epoch 038 | Train Loss: 0.158761                                                                                                   
Epoch 038 | Val Loss:   0.159708
current dict_size is:6489
Epoch 039 | Train Loss: 0.158777                                                                                                   
Epoch 039 | Val Loss:   0.159956
Epoch 040 | Train Loss: 0.158678                                                                                                   
Epoch 040 | Val Loss:   0.159456
current dict_size is:6584
→ Saved BEST model (val_loss=0.159456)
Epoch 041 | Train Loss: 0.158683                                                                                                   
Epoch 041 | Val Loss:   0.160131
Epoch 042 | Train Loss: 0.158591                                                                                                   
Epoch 042 | Val Loss:   0.159941
Epoch 043 | Train Loss: 0.158613                                                                                                   
Epoch 043 | Val Loss:   0.159763
Epoch 044 | Train Loss: 0.158576                                                                                                   
Epoch 044 | Val Loss:   0.159605
Epoch 045 | Train Loss: 0.158508                                                                                                   
Epoch 045 | Val Loss:   0.159643
Epoch 046 | Train Loss: 0.158464                                                                                                   
Epoch 046 | Val Loss:   0.159469
Epoch 047 | Train Loss: 0.158472                                                                                                   
Epoch 047 | Val Loss:   0.159537
Epoch 048 | Train Loss: 0.158420                                                                                                   
Epoch 048 | Val Loss:   0.159747
Epoch 049 | Train Loss: 0.158447                                                                                                   
Epoch 049 | Val Loss:   0.159449
current dict_size is:6997
→ Saved BEST model (val_loss=0.159449)
Epoch 050 | Train Loss: 0.158378                                                                                                   
Epoch 050 | Val Loss:   0.159365
current dict_size is:7042
→ Saved BEST model (val_loss=0.159365)
Epoch 051 | Train Loss: 0.158419                                                                                                   
Epoch 051 | Val Loss:   0.159761




# def forward(self, imgs):
    #     #Extract patch tokens
    #     with torch.no_grad():
    #         feats_all = self.dinov2.get_intermediate_layers(
    #                 imgs, n=self.layer_indices, reshape=False, return_class_token=False)
    #         feats_proc = [F.normalize(f, dim=-1) for f in feats_all]
    #         img_feats = torch.stack(feats_proc, dim=0).mean(0)           #average across 4 layers


    #     B, N, D = img_feats.shape
    #     img_feats_flat = img_feats.reshape(B * N, D)


    #     #Dictionary reconstruction
    #     retrieved, _ = self.dictionary.lookup(img_feats_flat, self.top_k, self.lookup)
    #     retrieved = retrieved.view(B, N, -1)


    #     #Patch reconstruction loss
    #     diff = (img_feats - retrieved).pow(2).sum(-1)
    
    #     L_recon = diff.mean()


    #     #Smoothness regularization
    #     h = int(N ** 0.5)
    #     diff_map = diff.view(B, h, h)
    #     L_smooth = (
    #         F.l1_loss(diff_map[:, :, 1:], diff_map[:, :, :-1]) + 
    #         F.l1_loss(diff_map[:, 1:, :], diff_map[:, :-1, :])
    #     )


    #     #Feature alignment (global mean)
    #     img_global = F.normalize(img_feats.mean(1), dim=-1)
    #     dict_mean = F.normalize(self.dictionary.keys.mean(0, keepdim=True), dim=-1)
    #     L_align = 1 - (img_global * dict_mean).sum(-1).mean()

    #     total_loss = L_recon + self.lambda_align * L_align + self.lambda_smooth * L_smooth
    #     return total_loss, L_recon, L_align, L_smooth